<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Smart Vein Finder | Felix Hering</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>Felix Hering</h1>
        <nav>
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="../about.html">About</a></li>
                <li><a href="../projects.html">Projects</a></li>
                <li><a href="../resume.html">Resume</a></li>
            </ul>
        </nav>
    </header>

    <main class="project-content">
        <article>
            <div class="project-header">
                <h1>FirstStick: Intelligent Vein Finder</h1>
                <p class="project-meta">Fall 2025 | Georgia Tech Create X</p> 
                <div class="project-tags">
                    <span class="tech-pill">Medical Device</span>
                    <span class="tech-pill">PCB Design (KiCad)</span>
                    <span class="tech-pill">NVIDIA Jetson Nano</span>
                    <span class="tech-pill">Computer Vision</span>
                    <span class="tech-pill">Machine Learning</span>
                    <span class="tech-pill">NIR Imaging</span>
                    <span class="tech-pill">Hardware Integration</span>
                </div>
            </div>

            <div class="project-content">
                
                <h2>Project Overview</h2>
                <p>As hardware lead on a four-person interdisciplinary team (two CS, one BME, one ME) in Georgia Tech's Create X startup program, I developed FirstStick: an affordable, intelligent vein-finding device that goes beyond simple visualization to provide algorithmic site recommendations for venipuncture.</p>
                
                <p>Unlike existing $4,000-$15,000 solutions that merely project vein images, our device uses multi-wavelength NIR imaging combined with real-time machine learning to rank veins by depth, diameter, and straightness, directly addressing the root cause of the 27% first-attempt failure rate in venipuncture procedures.</p>

                <div class="key-stats">
                    <div class="stat">
                        <h3>83%</h3>
                        <p>Agreement rate with clinician site selection in blind study (N=80 trials)</p>
                    </div>
                    <div class="stat">
                        <h3>$736</h3>
                        <p>Prototype BOM cost (target $300 in mass production)</p>
                    </div>
                    <div class="stat">
                        <h3>CNR > 2.5</h3>
                        <p>Maintained contrast-to-noise ratio even on Type VI skin tones</p>
                    </div>
                </div>

                <h2>The Clinical Problem</h2>
                <p>Through 90 customer discovery interviews with nurses, phlebotomists, and physicians across diverse clinical settings, we identified critical gaps in existing vein visualization technology:</p>
                
                <ul>
                    <li><strong>No Decision Support:</strong> Current devices show vein maps but don't recommend which vein to use, forcing clinicians to interpret raw images without algorithmic guidance</li>
                    <li><strong>Poor Performance on Darker Skin:</strong> Single-wavelength NIR systems show reduced effectiveness across melanin levels, contributing to healthcare disparities</li>
                    <li><strong>Cost Barriers:</strong> Ultrasound systems ($10,000+) and high-end NIR projectors ($4,000-$15,000) are inaccessible to smaller clinics</li>
                    <li><strong>Limited Depth Information:</strong> Existing solutions can't distinguish between superficial and deeper veins, leading to poor site selection</li>
                </ul>

                <h2>My Role: Hardware Lead & System Integration</h2>
                <p>As hardware lead, I owned the complete electronics design, component sourcing, and hardware-software integration. This included:</p>

                <h3>Camera System Selection & Integration</h3>
                <p>Selected and integrated the <strong>See3CAM_CU135M</strong> (AR1335 13MP monochrome sensor) for its exceptional NIR sensitivity. Configured the camera for 2×2 and 4×4 pixel binning to achieve usable frame rates under low-light NIR illumination while maintaining the resolution needed for 2mm vessel detection.</p>

                <h3>Custom PCB Design Evolution</h3>
                <p>Designed two iterations of the LED driver board in KiCad:</p>
                
                <div class="project-side-by-side">
                    <div class="text">
                        <h4>Version 1 (Failed)</h4>
                        <p>Initial design used LDD-350L constant-current drivers with an I2C PWM controller IC for coordinated LED switching. The board experienced catastrophic failure during testing due to:</p>
                        <ul>
                            <li>Incorrect SMD LED footprint orientation creating poor return paths</li>
                            <li>Complex LED driver interface that was difficult to debug</li>
                            <li>Insufficient grounding verification in the driver stage</li>
                        </ul>
                        <p>This failure was a critical learning experience in power electronics design and the importance of thorough grounding verification before fabrication.</p>
                    </div>
                    
                    <figure>
                        <img src="../pictures/vein_finder/v1_pcb_failure.png" alt="Version 1 PCB showing burn damage" style="max-width: 230px;">
                        <figcaption>Version 1 PCB after failure</figcaption>
                    </figure>
                </div>

                <h4>Version 2 (Production Prototype)</h4>
                <p>Completely redesigned with a simplified, robust architecture:</p>
                <ul>
                    <li><strong>Direct GPIO Control:</strong> Eliminated the problematic I2C controller; Jetson Nano GPIO pins now directly drive logic-level MOSFETs (one per wavelength channel)</li>
                    <li><strong>Discrete Current Limiting:</strong> Series resistors calculate LED current from the 12V supply, avoiding complex driver ICs during prototyping</li>
                    <li><strong>Improved Debuggability:</strong> Each LED channel can be tested independently with basic multimeter measurements</li>
                    <li><strong>Three-Wavelength Architecture:</strong> 6× 720nm LEDs, 3× 860nm LEDs, 3× 940nm LEDs arranged in a ring around the camera aperture</li>
                </ul>

                <figure>
                    <img src="../pictures/vein_finder/schematic.png" alt="Version 2 PCB Schematic" class="standard-img">
                    <figcaption>Simplified V2 schematic—MOSFETs with gate resistors/pull-downs, discrete LED current limiting</figcaption>
                </figure>

                <div class="side-by-side-container">
                    <figure>
                        <img src="../pictures/vein_finder/pcb_bottom.png" alt="PCB bottom with LED ring" style="max-width: 275px;">
                        <figcaption>PCB bottom view with LED ring</figcaption>
                    </figure>
                    <figure>
                        <img src="../pictures/vein_finder/pcb_top.png" alt="PCB top with MOSFETs" style="max-width: 400px;">
                        <figcaption>PCB top view with MOSFETs and protection circuitry</figcaption>
                    </figure>
                </div>

                <h3>Optical Design & Component Selection</h3>
                <ul>
                    <li><strong>Bandpass Filter:</strong> Sourced and integrated 700-1100nm filter to reject visible light and reduce ambient interference</li>
                    <li><strong>Diffuser System:</strong> Selected elliptical PMMA diffuser to eliminate LED hotspots and improve illumination uniformity—critical for stable segmentation performance</li>
                    <li><strong>Fixed Working Distance:</strong> Designed mechanical geometry to maintain ~8-inch camera-to-skin distance, optimizing for depth of field and contrast</li>
                </ul>

                <h3>Mechanical Design</h3>
                <p>Led the evolution from an unstable handheld concept to a robust C-shaped stand-mounted design:</p>
                <ul>
                    <li>Iteratively designed four interlocking FDM-printed PLA components with press-fit joints (10mm male / 10.25mm female geometry)</li>
                    <li>Added curved ergonomic arm rest to ensure repeatable patient positioning</li>
                    <li>Enlarged base and integrated non-slip silicone pad to eliminate tipping under lateral forces</li>
                    <li>Final assembly: 36 × 25 × 25 cm, 1.76 kg</li>
                </ul>

                <div class="side-by-side-container">
                    <figure>
                        <img src="../pictures/vein_finder/final_device.png" alt="Final assembled device" style="width: 1400px;">
                        <figcaption>Final C-shaped design with curved arm, integrated arm rest, and LCD mount</figcaption>
                    </figure>
                    <figure>
                        <img src="../pictures/vein_finder/exploded_view.png" alt="Exploded view of device assembly" style="max-width: 300px;">
                        <figcaption>Exploded view showing component integration: base, curved arm, top plate, imaging stack, and LCD lid</figcaption>
                    </figure>
                </div>


                <figure>
                    <img src="../pictures/vein_finder/internal_optics.png" alt="Internal view of imaging stack">
                    <figcaption>Internal view of the imaging stack: camera, LED ring, diffuser, and bandpass filter arrangement</figcaption>
                </figure>

                <h2>The Multi-Wavelength Physics</h2>
                <p>Our depth estimation approach is grounded in the wavelength-dependent optical properties of tissue:</p>
                
                <h3>Hemoglobin Absorption vs. Tissue Scattering Trade-off</h3>
                <ul>
                    <li><strong>740nm:</strong> Maximum hemoglobin absorption contrast but high tissue scattering—best for superficial veins</li>
                    <li><strong>860nm:</strong> Balanced penetration and absorption—works across skin tones</li>
                    <li><strong>940nm:</strong> Deepest penetration but reduced contrast due to water absorption</li>
                </ul>

                <p>By capturing three sequential exposures and comparing relative vein visibility across wavelengths, our U-Net-ResNet34 segmentation model can infer relative depth ordering without requiring absolute depth calibration.</p>

                <h2>System Architecture & Real-Time Operation</h2>
                <p>The complete imaging pipeline operates as follows:</p>

                <ol>
                    <li><strong>Sequential Capture:</strong> Jetson Nano GPIO toggles each wavelength bank via my PCB MOSFETs, captures synchronized frame from camera (time-multiplexed illumination)</li>
                    <li><strong>Preprocessing:</strong> CLAHE contrast enhancement, hair artifact removal via morphological filtering</li>
                    <li><strong>Segmentation:</strong> U-Net-ResNet34 model (trained on N=200 annotated images) produces binary vein mask</li>
                    <li><strong>Vein Ranking Algorithm:</strong> Analyzes each candidate vein for:
                        <ul>
                            <li>Relative depth (multi-wavelength visibility comparison)</li>
                            <li>Diameter (≥2mm threshold via full-width half-maximum)</li>
                            <li>Path straightness (curvature analysis)</li>
                        </ul>
                    </li>
                    <li><strong>Live Display:</strong> Overlay top 3 ranked sites on real-time video feed with confidence indicators</li>
                </ol>

                <figure>
                    <img src="../pictures/vein_finder/gui_interface.png" alt="User interface showing live vein overlay" class="standard-img">
                    <figcaption>User interface: live camera feed with ranked vein overlay and confidence indicators</figcaption>
                </figure>

                <p><strong>Performance:</strong> Achieved ~2 fps effective update rate on Jetson Nano prototype with sub-second total latency from capture to recommendation display.</p>

                <h2>Validation & Testing Results</h2>

                <h3>Contrast Performance Across Skin Tones</h3>
                <p>Conducted pixel-level CNR analysis across Fitzpatrick skin tone classifications (N=200 images), where contrast-to-noise ratio is defined as:</p>
                
                <p style="text-align:center; font-family: 'Courier New', monospace; font-size: 1.1rem; margin: 1rem 0;">
                    CNR = (μ<sub>background</sub> − μ<sub>vein</sub>) / σ<sub>background</sub>
                </p>

                <figure>
                    <img src="../pictures/vein_finder/cnr_plot.png" alt="CNR distribution across skin tones" class="standard-img">
                    <figcaption>CNR distribution across Fitzpatrick skin tone types—median CNR remains above 2.5 even for Type VI</figcaption>
                </figure>

                <p>Key findings:</p>
                <ul>
                    <li>Type I-II: Median CNR ≈ 4.0</li>
                    <li>Type V-VI: Median CNR ≈ 2.6-3.0</li>
                    <li><strong>All skin tones maintained CNR > 2.5</strong>—sufficient for reliable segmentation</li>
                </ul>

                <h3>Clinical Blind Study</h3>
                <p>8 phlebotomists, ~10 selections each (≈80 trials total):</p>
                <ul>
                    <li><strong>83% agreement rate</strong> between clinician first choice and device top-ranked recommendation</li>
                    <li>Validation that algorithmic ranking aligns with expert clinical judgment</li>
                    <li><em>Limitation:</em> Dataset skewed young/male; lacks elderly and diverse body types</li>
                </ul>

                <h3>Algorithm Performance</h3>
                <ul>
                    <li>U-Net segmentation accuracy: ~92% on internal test split</li>
                    <li>Inference + display latency: typically <0.4s per frame update</li>
                </ul>
                <h2>Live Demo</h2>
                <p>The video below demonstrates FirstStick operating in real-time on an actual subject. Watch as the device continuously analyzes the vein structure and provides live recommendations for the optimal venipuncture site. The faint red light flashing throughout the video is the 720nm NIR LED bank cycling during the multi-wavelength capture sequence.</p>

                <figure>
                    <video controls class="standard-img" style="max-width: 800px;">
                        <source src="../pictures/vein_finder/live_demo.mp4" type="video/mp4">
                    </video>
                    <figcaption>Live demonstration showing real-time vein detection and site ranking.</figcaption>
                </figure>

                <p><strong>What you're seeing:</strong></p>
                <ul>
                    <li>Real-time segmentation and overlay of detected veins</li>
                    <li>Top 3 ranked venipuncture sites highlighted with confidence indicators</li>
                    <li>System operating at ~2 fps effective update rate</li>
                    <li>Faint red glow from 740nm LEDs during capture sequence (740nm, 860nm, 940nm cycling)</li>
                </ul>

                <h2>Project Impact</h2>
                <p>FirstStick addresses a clear unmet clinical need—affordable, intelligent venipuncture guidance for underserved clinics. By combining multi-wavelength NIR imaging with real-time machine learning, we've demonstrated feasibility of a system that not only visualizes veins but recommends optimal sites, working equitably across skin tones. The 83% agreement rate with expert clinicians in our blind study validates the core technology, while the <$300 production cost target makes the solution accessible to resource-constrained healthcare settings.</p>

                <div class="project-links">
                    <a href="../files/Team5_Report3_Fall2025.pdf" class="button" target="_blank">View Full Technical Report</a>
                </div>
            </div>
        </article>
    </main>

    <footer>
        <p>&copy; 2025 Felix Hering</p>
    </footer>
</body>
</html>

